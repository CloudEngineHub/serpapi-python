<%-
def snippet(format, path, start, stop) 
 slice = File.new(path).readlines[start..stop]
 slice.reject! { |l| l.match?(/self.assertIsNone\(/) || l.match?(/# os\.getenv\("API_KEY"\)/) }
 buf = slice.map { |l| l.gsub(/(^\s{4})/, '').gsub(/^\s*$/, '') }.join
 buf.gsub!('self.assertIsNotNone(', "pp = pprint.PrettyPrinter(indent=2)\npp.pprint(")
 %Q(```#{format}\nimport serpapi\nimport pprint\nimport os\n\n#{buf}```\ntest: #{path})
end
-%>
# User guide
[![SerpApi-Python](https://github.com/serpapi/serpapi-python/actions/workflows/ci.yml/badge.svg)](https://github.com/serpapi/serpapi-python/actions/workflows/ci.yml)

[SerpApi](https://serpapi.com) allows to scrape any search engine results.
It's easy, fast, easy, feature rich, cost effective, scalable and reliable.

This Python 3 library is meant to scrape and parse results from all major search engines available world wide including Google, Bing, Baidu, Yandex, Yahoo, Ebay, Home depot, Apple and more using [SerpApi](https://serpapi.com).
This is an open source project hosted under https://github.com/serpapi/serpapi-python.

SerpApi.com provides a [script builder](https://serpapi.com/demo) to get you started quickly.

## Installation
SerpApi can be installed with pip.

```sh
$ python -m pip install serpapi
```

## Quick start

The following example runs a search for `"coffee"` using your secret API key which you can find at [SerpApi Dashboard](https://serpapi.com/manage-api-key) page. The `serpapi.search` object handles all of the details of connection pooling and thread safety so that you don't have to:

```python
import serpapi

client = serpapi.Client(
  api_key = "secret_api_key", # from serpapi.com
)

parameters = {
  "q": "coffee",
}

results = client.search(parameters)

print(results)
```

### Advanced settings
SerpApi Client uses urllib3 under the hood.

Optionally, the HTTP connection can be tuned:
  - timeout : connection timeout by default 60s
  - retries : attempt to reconnect if the connection failed by default: False. Documentation: https://urllib3.readthedocs.io/en/stable/reference/urllib3.util.html#urllib3.util.Retry
  - api_key : the secret user API available from http://serpapi.com/manage-api-key

   SerpApi's SLA is 99.95% successful searches: https://serpapi.com/faq/general/do-you-provide-sla-guarantees

```python
client = serpapi.Client(
  retries = 5, # or urllib3.util.Retry(connect=5, read=2)
  timeout = 4.2,
  api_key = "secret_api_key", # from serpapi.com
)
```

For more details: [`urllib3` documentation](https://urllib3.readthedocs.io/en/stable/user-guide.html)

## Basic example per search engines

<%- Dir.glob('tests/example_search_*.py').each do |example| -%>
<% engine = example.match('example_search_(\w+)\.py')[1] %>

### Search <%= engine.split('_').map(&:capitalize).join(' ') %>
<%= snippet('python', "tests/example_search_#{engine}.py", 9, 40) %>
<br>
Documentation: https://serpapi.com/<%= engine.tr('_', '-') %>-search-api
<%- end -%>

# Developer Guide
### Key goals
 - High code quality
 - KISS principles
 - Brand centric instead of search engine based
   - No hard coded logic per search engine
 - Simple HTTP client (lightweight, reduced dependency)
   - No magic default values
   - Thread safe
 - Easy to extends
 - Defensive code style (raise custom exception)
 - TDD
 - Best API coding pratice per platform

### Inspiration
The API design was inpired by the most popular Python packages.
 - urllib3 - https://github.com/urllib3/urllib3
 - Boto3 - https://github.com/boto/boto3

### Quality expectation
 - 0 lint issues using pylint `make lint`
 - 99% code coverage running `make test`
 - 100% test passing: `make test`
 
### Client design: Class diagram
```mermaid
classDiagram
  CustomClient *-- Client
  HttpClient <-- Client
  HttpClient *-- urllib3
  HttpClient *-- ObjectDecoder

  class Client {
    engine: String
    api_key: String
    parameter: Hash
    search()
    html()
    location()
    search_archive()
    account()
  }

  class HttpClient {
    start()
    decode()
  }

  class urllib3 {
    request()
  }
```

## JSON search() : Sequence diagram
```mermaid
sequenceDiagram
    Client->>SerpApi.com: search() : http request 
    SerpApi.com-->>SerpApi.com: query search engine
    SerpApi.com-->>SerpApi.com: parse HTML into JSON
    SerpApi.com-->>Client: JSON payload
    Client-->>Client: decode JSON into Dict
```

## Build flow

This project is automated using a good old Makefile.
To pipe-clean the project run this:
`make`

Open Makefile for more details.
